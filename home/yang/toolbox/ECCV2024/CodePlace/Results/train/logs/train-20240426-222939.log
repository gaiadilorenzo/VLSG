[2024-04-26 22:29:39] [INFO] Command executed: ./src/trainval/trainval_patchobj_TXAE_SGIAE.py --config ./scripts/train_val/train.yaml
[2024-04-26 22:29:39] [INFO] Configs:
{
    "data": {
        "name": "Scan3R",
        "root_dir": "/home/yang/big_ssd/Scan3R/3RScan",
        "rescan": true,
        "temporal": true,
        "resplit": true,
        "img": {
            "img_step": 1,
            "w": 960,
            "h": 540
        },
        "img_encoding": {
            "resize_w": 1024,
            "img_rotate": true,
            "patch_w": 16,
            "patch_h": 9,
            "record_feature": false,
            "use_feature": true,
            "preload_feature": false,
            "feature_dir": "Features2D/DinoV2_16_9_scan",
            "resize_h": 576
        },
        "cross_scene": {
            "use_cross_scene": true,
            "num_scenes": 9,
            "num_negative_samples": -1,
            "use_tf_idf": false
        },
        "scene_graph": {
            "obj_img_patch": "Features3D/obj_dinov2_top10_l3",
            "obj_patch_num": 100,
            "obj_topk": 10,
            "use_predicted": false
        },
        "auxiliary": {
            "use_patch_depth": false,
            "depth_dir": ""
        }
    },
    "model": {
        "backbone": {
            "name": "GCViT",
            "cfg_file": "/home/yang/toolbox/ECCV2024/CodePlace/OfficialCode/VLSG/./src/models/GCVit/configs/gcvit/cascade_mask_rcnn_gcvit_tiny_3x_coco.py",
            "pretrained": "/home/yang/toolbox/ECCV2024/CodePlace/OfficialCode/VLSG/./checkpoint/GCVit/gcvit_1k_tiny.pth.tar",
            "use_pretrained": false,
            "num_reduce": 0,
            "backbone_dim": 1536
        },
        "patch": {
            "hidden_dims": [
                512
            ],
            "encoder_dim": 400,
            "gcn_layers": 2
        },
        "obj": {
            "embedding_dim": 656,
            "embedding_hidden_dims": [
                512,
                512
            ],
            "encoder_dim": 400
        },
        "other": {
            "drop": 0.1
        },
        "global_descriptor_dim": 1024
    },
    "sgaligner": {
        "modules": [
            "point",
            "gat",
            "rel",
            "attr",
            "img_patch"
        ],
        "use_pos_enc": true,
        "use_pretrained": false,
        "pretrained": "",
        "label_file_name": "labels.instances.annotated.v2.ply",
        "pred_subfix": "inseg.ply",
        "seed": 42,
        "model_name": "sgaligner",
        "use_predicted": false,
        "registration": false,
        "scan_type": "scan",
        "img_transformer": false,
        "preprocess": {
            "pc_resolutions": [
                64,
                128,
                256,
                512
            ],
            "subscenes_per_scene": 1,
            "filter_segment_size": 512,
            "min_obj_points": 50,
            "anchor_type_name": ""
        },
        "model": {
            "rel_dim": 41,
            "attr_dim": 164,
            "img_patch_feat_dim": 1536,
            "img_emb_dim": 256,
            "alignment_thresh": 0.4,
            "multi_view_aggregator": "transformer"
        },
        "train": {
            "pc_res": 512
        },
        "val": {
            "pc_res": 512,
            "overlap_low": 0.0,
            "overlap_high": 0.0,
            "data_mode": "orig"
        }
    },
    "train": {
        "gpus": 1,
        "precision": 16,
        "batch_size": 16,
        "num_workers": 16,
        "freeze_backbone": false,
        "use_pretrained": false,
        "log_steps": 20,
        "snapshot_steps": 1,
        "optim": {
            "lr": 0.0011,
            "scheduler": "step",
            "lr_decay": 0.97,
            "lr_decay_steps": 1,
            "lr_min": 0.0005,
            "T_max": 1000,
            "T_mult": 1,
            "weight_decay": 1e-06,
            "max_epoch": 10500,
            "free_backbone_epoch": 10500,
            "grad_acc_steps": 1,
            "free_sgaligner_epoch": -1
        },
        "loss": {
            "use_temporal": true,
            "loss_type": "ICLLossBothSidesSumOutLog",
            "alpha": 0.5,
            "temperature": 0.1,
            "margin": 0.5,
            "epsilon": 1e-08,
            "use_global_descriptor": false,
            "global_loss_coef": 0.5,
            "global_desc_temp": 1.0
        },
        "use_vis": false,
        "vis_epoch_steps": 100,
        "data_aug": {
            "use_aug": true,
            "img": {
                "rotation": 60.0,
                "horizontal_flip": 0.5,
                "vertical_flip": 0.5,
                "color": 0.3
            },
            "use_aug_3D": true,
            "pcs": {
                "granularity": [
                    0.05,
                    0.2,
                    0.4
                ],
                "magnitude": [
                    0.2,
                    0.4,
                    0.4
                ]
            }
        }
    },
    "val": {
        "batch_size": 16,
        "num_workers": 16,
        "pretrained": "./",
        "room_retrieval": {
            "retrieval": false,
            "epsilon_th": 0.8,
            "method_name": ""
        }
    },
    "other": {
        "use_resume": false,
        "resume": "home/yang/toolbox/ECCV2024/CodePlace/Results/train/./snapshots/epoch-8.pth.tar",
        "resume_folder": ""
    },
    "model_name": "ObjectPatchAligner",
    "output_dir": "home/yang/toolbox/ECCV2024/CodePlace/Results/train",
    "mode": "train",
    "seed": 42,
    "snapshot_dir": "home/yang/toolbox/ECCV2024/CodePlace/Results/train/snapshots",
    "log_dir": "home/yang/toolbox/ECCV2024/CodePlace/Results/train/logs",
    "event_dir": "home/yang/toolbox/ECCV2024/CodePlace/Results/train/events"
}
[2024-04-26 22:29:39] [DEBU] Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[2024-04-26 22:29:39] [DEBU] Creating converter from 7 to 5
[2024-04-26 22:29:39] [DEBU] Creating converter from 5 to 7
[2024-04-26 22:29:39] [DEBU] Creating converter from 7 to 5
[2024-04-26 22:29:39] [DEBU] Creating converter from 5 to 7
[2024-04-26 22:29:40] [INFO] Tensorboard is enabled. Write events to home/yang/toolbox/ECCV2024/CodePlace/Results/train/events.
[2024-04-26 22:29:40] [INFO] Using Single-GPU mode
[2024-04-26 22:30:24] [INFO] Data loader created: 44.325s collapsed.
[2024-04-26 22:30:25] [INFO] Model description:
PatchSGIEAligner(
  (reduce_layers): EncodeChannelSize(
    (conv): Sequential(
      (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
      (1): GELU(approximate='none')
      (2): SE(
        (avg_pool): AdaptiveAvgPool2d(output_size=1)
        (fc): Sequential(
          (0): Linear(in_features=1536, out_features=384, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=384, out_features=1536, bias=False)
          (3): Sigmoid()
        )
      )
      (3): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  )
  (patch_encoder): Mlps(
    (mlp_layers): Sequential(
      (0): Linear(in_features=1536, out_features=512, bias=True)
      (1): GELU(approximate='none')
      (2): Dropout(p=0.1, inplace=False)
      (3): Linear(in_features=512, out_features=400, bias=True)
      (4): Dropout(p=0.1, inplace=False)
    )
  )
  (patch_gcn): PatchCNN(
    (blocks): Sequential(
      (0): Residual(
        (conv1): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (sg_encoder): MultiModalEncoder(
    (object_encoder): PointNetfeat(
      (relu): ReLU()
      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))
      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
      (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (object_embedding): Linear(in_features=256, out_features=100, bias=True)
    (structure_encoder): MultiGAT(
      (layer_stack): ModuleList(
        (0): GATConv(3, 128, heads=2)
        (1): GATConv(256, 128, heads=2)
      )
    )
    (structure_embedding): Linear(in_features=256, out_features=100, bias=True)
    (meta_embedding_rel): Linear(in_features=41, out_features=100, bias=True)
    (meta_embedding_attr): Linear(in_features=164, out_features=100, bias=True)
    (img_patch_encoder): Mlps(
      (mlp_layers): Sequential(
        (0): Linear(in_features=1536, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=512, out_features=256, bias=True)
        (4): Dropout(p=0.0, inplace=False)
      )
    )
    (pose_encoder): Mlps(
      (mlp_layers): Sequential(
        (0): Linear(in_features=7, out_features=128, bias=True)
        (1): GELU(approximate='none')
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=128, out_features=256, bias=True)
        (4): Dropout(p=0.0, inplace=False)
      )
    )
    (multiview_encoder): PatchAggregator(
      (transformer_encoder): TransformerEncoderLayer(
        (self_attn): Attention(
          (softmax): Softmax(dim=-1)
          (to_qkv): Linear(in_features=256, out_features=768, bias=True)
          (to_out): Linear(in_features=256, out_features=256, bias=False)
        )
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (acti_layer): GELU(approximate='none')
      )
    )
    (multiview_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (img_patch_embedding): Linear(in_features=256, out_features=256, bias=True)
    (fusion): MultiModalFusion()
  )
  (obj_embedding_encoder): Mlps(
    (mlp_layers): Sequential(
      (0): Linear(in_features=656, out_features=512, bias=True)
      (1): GELU(approximate='none')
      (2): Dropout(p=0.1, inplace=False)
      (3): Linear(in_features=512, out_features=512, bias=True)
      (4): GELU(approximate='none')
      (5): Dropout(p=0.1, inplace=False)
      (6): Linear(in_features=512, out_features=400, bias=True)
      (7): Dropout(p=0.1, inplace=False)
    )
  )
)
[2024-04-26 22:30:25] [INFO] Initialisation Complete
[2024-04-26 22:31:38] [INFO] Epoch: 1/10500, iter: 20/17919, loss: 6.547900, loss_NT: 6.554898, loss_T: 6.540901, matched_success_ratio_NT: 0.003031, matched_success_ratio_T: 0.004353, lr: 0.001100, lr: 1.100e-03, time: 3.362s/2.566s
[2024-04-26 22:32:11] [INFO] Epoch: 1/10500, iter: 40/17919, loss: 6.199419, loss_NT: 6.208358, loss_T: 6.190480, matched_success_ratio_NT: 0.003873, matched_success_ratio_T: 0.006839, lr: 0.001100, lr: 1.100e-03, time: 1.754s/2.024s
